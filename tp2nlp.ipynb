{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9d7ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:30.794936Z",
     "iopub.status.busy": "2024-03-20T15:20:30.794518Z",
     "iopub.status.idle": "2024-03-20T15:20:32.242165Z",
     "shell.execute_reply": "2024-03-20T15:20:32.240724Z"
    },
    "papermill": {
     "duration": 1.458912,
     "end_time": "2024-03-20T15:20:32.244945",
     "exception": false,
     "start_time": "2024-03-20T15:20:30.786033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "full_df = pd.read_csv(\"/kaggle/input/movie-review/movie_review.csv\")\n",
    "df = full_df[[\"text\"]].copy()\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf99aaa",
   "metadata": {
    "papermill": {
     "duration": 0.006312,
     "end_time": "2024-03-20T15:20:32.258252",
     "exception": false,
     "start_time": "2024-03-20T15:20:32.251940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing des donn√©es****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f05e7b",
   "metadata": {
    "papermill": {
     "duration": 0.006347,
     "end_time": "2024-03-20T15:20:32.271424",
     "exception": false,
     "start_time": "2024-03-20T15:20:32.265077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Suppression des stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b46c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:32.286690Z",
     "iopub.status.busy": "2024-03-20T15:20:32.286319Z",
     "iopub.status.idle": "2024-03-20T15:20:35.209295Z",
     "shell.execute_reply": "2024-03-20T15:20:35.208035Z"
    },
    "papermill": {
     "duration": 2.934006,
     "end_time": "2024-03-20T15:20:35.212097",
     "exception": false,
     "start_time": "2024-03-20T15:20:32.278091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \n",
       "0  films adapted comic books plenty success , whe...  \n",
       "1  starters , created alan moore ( eddie campbell...  \n",
       "2  say moore campbell thoroughly researched subje...  \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...  \n",
       "4                      words , dismiss film source .  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def remove_stop_words(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "df[\"text_wo_stop_words\"] = df[\"text\"].apply(lambda text: remove_stop_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3f947",
   "metadata": {
    "papermill": {
     "duration": 0.007142,
     "end_time": "2024-03-20T15:20:35.226610",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.219468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "mise en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650e42b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:35.242402Z",
     "iopub.status.busy": "2024-03-20T15:20:35.241995Z",
     "iopub.status.idle": "2024-03-20T15:20:35.283254Z",
     "shell.execute_reply": "2024-03-20T15:20:35.281819Z"
    },
    "papermill": {
     "duration": 0.052128,
     "end_time": "2024-03-20T15:20:35.285940",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.233812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                          text_lower  \n",
       "0  films adapted comic books plenty success , whe...  \n",
       "1  starters , created alan moore ( eddie campbell...  \n",
       "2  say moore campbell thoroughly researched subje...  \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...  \n",
       "4                      words , dismiss film source .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_lower\"] = df[\"text_wo_stop_words\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3e472",
   "metadata": {
    "papermill": {
     "duration": 0.007677,
     "end_time": "2024-03-20T15:20:35.301409",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.293732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Suppression de ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd56817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:35.317955Z",
     "iopub.status.busy": "2024-03-20T15:20:35.317538Z",
     "iopub.status.idle": "2024-03-20T15:20:35.673643Z",
     "shell.execute_reply": "2024-03-20T15:20:35.672421Z"
    },
    "papermill": {
     "duration": 0.367659,
     "end_time": "2024-03-20T15:20:35.676363",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.308704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success  whet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters  created alan moore  eddie campbell  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book   graphic novel    500 pages long include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words  dismiss film source</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  films adapted comic books plenty success  whet...  \n",
       "1  starters  created alan moore  eddie campbell  ...  \n",
       "2  say moore campbell thoroughly researched subje...  \n",
       "3  book   graphic novel    500 pages long include...  \n",
       "4                        words  dismiss film source   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuation = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', punctuation))\n",
    "df[\"preprocessed_text\"] = df[\"text_wo_stop_words\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a613f8c",
   "metadata": {
    "papermill": {
     "duration": 0.007868,
     "end_time": "2024-03-20T15:20:35.691936",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.684068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Entrainement du mod√®le Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517f1518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:35.710352Z",
     "iopub.status.busy": "2024-03-20T15:20:35.709121Z",
     "iopub.status.idle": "2024-03-20T15:20:50.014370Z",
     "shell.execute_reply": "2024-03-20T15:20:50.013101Z"
    },
    "papermill": {
     "duration": 14.317691,
     "end_time": "2024-03-20T15:20:50.017202",
     "exception": false,
     "start_time": "2024-03-20T15:20:35.699511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success  whet...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters  created alan moore  eddie campbell  ...</td>\n",
       "      <td>[starters, created, alan, moore, eddie, campbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>[say, moore, campbell, thoroughly, researched,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book   graphic novel    500 pages long include...</td>\n",
       "      <td>[book, graphic, novel, 500, pages, long, inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words  dismiss film source</td>\n",
       "      <td>[words, dismiss, film, source]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  films adapted comic books plenty success  whet...   \n",
       "1  starters  created alan moore  eddie campbell  ...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book   graphic novel    500 pages long include...   \n",
       "4                        words  dismiss film source    \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [films, adapted, comic, books, plenty, success...  \n",
       "1  [starters, created, alan, moore, eddie, campbe...  \n",
       "2  [say, moore, campbell, thoroughly, researched,...  \n",
       "3  [book, graphic, novel, 500, pages, long, inclu...  \n",
       "4                     [words, dismiss, film, source]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df[\"tokenized_text\"] = df[\"preprocessed_text\"].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2e19c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:20:50.034828Z",
     "iopub.status.busy": "2024-03-20T15:20:50.034366Z",
     "iopub.status.idle": "2024-03-20T15:21:18.485708Z",
     "shell.execute_reply": "2024-03-20T15:21:18.484185Z"
    },
    "papermill": {
     "duration": 28.463183,
     "end_time": "2024-03-20T15:21:18.488312",
     "exception": false,
     "start_time": "2024-03-20T15:20:50.025129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>word_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success  whet...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[[-1.0533507, 0.2111854, 0.7168706, 0.86349934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters  created alan moore  eddie campbell  ...</td>\n",
       "      <td>[starters, created, alan, moore, eddie, campbe...</td>\n",
       "      <td>[[-0.027641581, 0.017273474, 0.030309223, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>[say, moore, campbell, thoroughly, researched,...</td>\n",
       "      <td>[[-0.7298285, 0.9981885, -0.01141301, 0.341162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book   graphic novel    500 pages long include...</td>\n",
       "      <td>[book, graphic, novel, 500, pages, long, inclu...</td>\n",
       "      <td>[[-0.3657412, 0.301753, 0.65252155, -0.0525106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words  dismiss film source</td>\n",
       "      <td>[words, dismiss, film, source]</td>\n",
       "      <td>[[-0.322295, 0.4877711, 0.33561867, -0.0959588...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  films adapted comic books plenty success  whet...   \n",
       "1  starters  created alan moore  eddie campbell  ...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book   graphic novel    500 pages long include...   \n",
       "4                        words  dismiss film source    \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [starters, created, alan, moore, eddie, campbe...   \n",
       "2  [say, moore, campbell, thoroughly, researched,...   \n",
       "3  [book, graphic, novel, 500, pages, long, inclu...   \n",
       "4                     [words, dismiss, film, source]   \n",
       "\n",
       "                                        word_vectors  \n",
       "0  [[-1.0533507, 0.2111854, 0.7168706, 0.86349934...  \n",
       "1  [[-0.027641581, 0.017273474, 0.030309223, -0.0...  \n",
       "2  [[-0.7298285, 0.9981885, -0.01141301, 0.341162...  \n",
       "3  [[-0.3657412, 0.301753, 0.65252155, -0.0525106...  \n",
       "4  [[-0.322295, 0.4877711, 0.33561867, -0.0959588...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model =  Word2Vec(sentences = df[\"tokenized_text\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "df[\"word_vectors\"] = None\n",
    "for i, tokenized_text in enumerate(df[\"tokenized_text\"]):\n",
    "    word_vectors = []\n",
    "    for token in tokenized_text:\n",
    "        if token in model.wv:\n",
    "            word_vector = model.wv[token]\n",
    "            word_vectors.append(word_vector)\n",
    "    df.at[i, 'word_vectors'] = word_vectors\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e5f36",
   "metadata": {
    "papermill": {
     "duration": 0.007967,
     "end_time": "2024-03-20T15:21:18.505171",
     "exception": false,
     "start_time": "2024-03-20T15:21:18.497204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vectorisation des reviews de movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dbb8c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:21:18.525075Z",
     "iopub.status.busy": "2024-03-20T15:21:18.524430Z",
     "iopub.status.idle": "2024-03-20T15:21:22.882144Z",
     "shell.execute_reply": "2024-03-20T15:21:22.880463Z"
    },
    "papermill": {
     "duration": 4.370661,
     "end_time": "2024-03-20T15:21:22.884910",
     "exception": false,
     "start_time": "2024-03-20T15:21:18.514249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stop_words</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>word_vectors</th>\n",
       "      <th>review_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success , whe...</td>\n",
       "      <td>films adapted comic books plenty success  whet...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[[-1.0533507, 0.2111854, 0.7168706, 0.86349934...</td>\n",
       "      <td>[-0.3573358, 0.43363076, 0.3361319, -0.0330491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters , created alan moore ( eddie campbell...</td>\n",
       "      <td>starters  created alan moore  eddie campbell  ...</td>\n",
       "      <td>[starters, created, alan, moore, eddie, campbe...</td>\n",
       "      <td>[[-0.027641581, 0.017273474, 0.030309223, -0.0...</td>\n",
       "      <td>[-0.20687117, 0.15761329, 0.31639022, -0.18995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>[say, moore, campbell, thoroughly, researched,...</td>\n",
       "      <td>[[-0.7298285, 0.9981885, -0.01141301, 0.341162...</td>\n",
       "      <td>[-0.33312535, 0.486958, 0.32377997, -0.1588604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book ( \" graphic novel , \" ) 500 pages long in...</td>\n",
       "      <td>book   graphic novel    500 pages long include...</td>\n",
       "      <td>[book, graphic, novel, 500, pages, long, inclu...</td>\n",
       "      <td>[[-0.3657412, 0.301753, 0.65252155, -0.0525106...</td>\n",
       "      <td>[-0.2420425, 0.2460383, 0.26388946, -0.0148352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words , dismiss film source .</td>\n",
       "      <td>words  dismiss film source</td>\n",
       "      <td>[words, dismiss, film, source]</td>\n",
       "      <td>[[-0.322295, 0.4877711, 0.33561867, -0.0959588...</td>\n",
       "      <td>[-0.274918, 0.23367628, 0.40009725, 0.27528965...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters , it was created by alan moore ( ...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book ( or \" graphic novel , \" if you will ...   \n",
       "4  in other words , don't dismiss this film becau...   \n",
       "\n",
       "                                  text_wo_stop_words  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  films adapted comic books plenty success , whe...   \n",
       "1  starters , created alan moore ( eddie campbell...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book ( \" graphic novel , \" ) 500 pages long in...   \n",
       "4                      words , dismiss film source .   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  films adapted comic books plenty success  whet...   \n",
       "1  starters  created alan moore  eddie campbell  ...   \n",
       "2  say moore campbell thoroughly researched subje...   \n",
       "3  book   graphic novel    500 pages long include...   \n",
       "4                        words  dismiss film source    \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [starters, created, alan, moore, eddie, campbe...   \n",
       "2  [say, moore, campbell, thoroughly, researched,...   \n",
       "3  [book, graphic, novel, 500, pages, long, inclu...   \n",
       "4                     [words, dismiss, film, source]   \n",
       "\n",
       "                                        word_vectors  \\\n",
       "0  [[-1.0533507, 0.2111854, 0.7168706, 0.86349934...   \n",
       "1  [[-0.027641581, 0.017273474, 0.030309223, -0.0...   \n",
       "2  [[-0.7298285, 0.9981885, -0.01141301, 0.341162...   \n",
       "3  [[-0.3657412, 0.301753, 0.65252155, -0.0525106...   \n",
       "4  [[-0.322295, 0.4877711, 0.33561867, -0.0959588...   \n",
       "\n",
       "                                       review_vector  \n",
       "0  [-0.3573358, 0.43363076, 0.3361319, -0.0330491...  \n",
       "1  [-0.20687117, 0.15761329, 0.31639022, -0.18995...  \n",
       "2  [-0.33312535, 0.486958, 0.32377997, -0.1588604...  \n",
       "3  [-0.2420425, 0.2460383, 0.26388946, -0.0148352...  \n",
       "4  [-0.274918, 0.23367628, 0.40009725, 0.27528965...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review_vector\"] = None\n",
    "reviews_list = df['text'].apply(lambda x: x.split()).tolist()\n",
    "for i, word_vectors in enumerate(df[\"word_vectors\"]):\n",
    "    if len(word_vectors) > 0:\n",
    "        average_vector = np.mean(word_vectors, axis=0)\n",
    "        df.at[i, \"review_vector\"] = average_vector\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6e9b7",
   "metadata": {
    "papermill": {
     "duration": 0.008278,
     "end_time": "2024-03-20T15:21:22.903285",
     "exception": false,
     "start_time": "2024-03-20T15:21:22.895007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Division des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25c023e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:21:22.923169Z",
     "iopub.status.busy": "2024-03-20T15:21:22.922748Z",
     "iopub.status.idle": "2024-03-20T15:21:22.967782Z",
     "shell.execute_reply": "2024-03-20T15:21:22.966180Z"
    },
    "papermill": {
     "duration": 0.058296,
     "end_time": "2024-03-20T15:21:22.970615",
     "exception": false,
     "start_time": "2024-03-20T15:21:22.912319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(full_df['tag'].unique())\n",
    "df['tag'] = le.fit_transform(full_df['tag'])\n",
    "# D√©finir les features  et la target \n",
    "X = df[\"review_vector\"].values\n",
    "y = df[\"tag\"].values\n",
    "\n",
    "\n",
    "#Diviser les donn√©es en train set et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd302f4",
   "metadata": {
    "papermill": {
     "duration": 0.008242,
     "end_time": "2024-03-20T15:21:22.987580",
     "exception": false,
     "start_time": "2024-03-20T15:21:22.979338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Construction d'un classificateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20377134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:21:23.007783Z",
     "iopub.status.busy": "2024-03-20T15:21:23.007379Z",
     "iopub.status.idle": "2024-03-20T15:21:23.015585Z",
     "shell.execute_reply": "2024-03-20T15:21:23.014181Z"
    },
    "papermill": {
     "duration": 0.02196,
     "end_time": "2024-03-20T15:21:23.018321",
     "exception": false,
     "start_time": "2024-03-20T15:21:22.996361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import LogisticRegression\\n\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337cdcd",
   "metadata": {
    "papermill": {
     "duration": 0.008967,
     "end_time": "2024-03-20T15:21:23.036171",
     "exception": false,
     "start_time": "2024-03-20T15:21:23.027204",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24bac23",
   "metadata": {
    "papermill": {
     "duration": 0.009274,
     "end_time": "2024-03-20T15:21:23.054185",
     "exception": false,
     "start_time": "2024-03-20T15:21:23.044911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e195777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T15:21:23.074464Z",
     "iopub.status.busy": "2024-03-20T15:21:23.074003Z",
     "iopub.status.idle": "2024-03-20T15:21:23.081285Z",
     "shell.execute_reply": "2024-03-20T15:21:23.079885Z"
    },
    "papermill": {
     "duration": 0.020334,
     "end_time": "2024-03-20T15:21:23.083761",
     "exception": false,
     "start_time": "2024-03-20T15:21:23.063427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred=logistic_model.predict(X_test)\\nlogistic_model.score(X_test,y_test)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred=logistic_model.predict(X_test)\n",
    "logistic_model.score(X_test,y_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4133,
     "sourceId": 8841,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2052,
     "sourceId": 131084,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.075873,
   "end_time": "2024-03-20T15:21:24.518207",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-20T15:20:27.442334",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
